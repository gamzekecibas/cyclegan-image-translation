{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import libraries\n",
    "\"\"\"\n",
    "The following is an import of PyTorch libraries.\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Determine if any GPUs are available\n",
    "\"\"\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A Convolutional Variational Autoencoder\n",
    "\"\"\"\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, imgChannels=1, featureDim=32*20*20, zDim=256):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        # Initializing the 2 convolutional layers and 2 full-connected layers for the encoder\n",
    "        self.encConv1 = nn.Conv2d(imgChannels, 16, 5)\n",
    "        self.encConv2 = nn.Conv2d(16, 32, 5)\n",
    "        self.encFC1 = nn.Linear(featureDim, zDim)\n",
    "        self.encFC2 = nn.Linear(featureDim, zDim)\n",
    "\n",
    "        # Initializing the fully-connected layer and 2 convolutional layers for decoder\n",
    "        self.decFC1 = nn.Linear(zDim, featureDim)\n",
    "        self.decConv1 = nn.ConvTranspose2d(32, 16, 5)\n",
    "        self.decConv2 = nn.ConvTranspose2d(16, imgChannels, 5)\n",
    "\n",
    "    def encoder(self, x):\n",
    "\n",
    "        # Input is fed into 2 convolutional layers sequentially\n",
    "        # The output feature map are fed into 2 fully-connected layers to predict mean (mu) and variance (logVar)\n",
    "        # Mu and logVar are used for generating middle representation z and KL divergence loss\n",
    "        x = F.relu(self.encConv1(x))\n",
    "        x = F.relu(self.encConv2(x))\n",
    "        x = x.view(-1, 32*20*20)\n",
    "        mu = self.encFC1(x)\n",
    "        logVar = self.encFC2(x)\n",
    "        return mu, logVar\n",
    "\n",
    "    def reparameterize(self, mu, logVar):\n",
    "\n",
    "        #Reparameterization takes in the input mu and logVar and sample the mu + std * eps\n",
    "        std = torch.exp(logVar/2)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + std * eps\n",
    "\n",
    "    def decoder(self, z):\n",
    "\n",
    "        # z is fed back into a fully-connected layers and then into two transpose convolutional layers\n",
    "        # The generated output is the same size of the original input\n",
    "        x = F.relu(self.decFC1(z))\n",
    "        x = x.view(-1, 32, 20, 20)\n",
    "        x = F.relu(self.decConv1(x))\n",
    "        x = torch.sigmoid(self.decConv2(x))\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # The entire pipeline of the VAE: encoder -> reparameterization -> decoder\n",
    "        # output, mu, and logVar are returned for loss computation\n",
    "        mu, logVar = self.encoder(x)\n",
    "        z = self.reparameterize(mu, logVar)\n",
    "        out = self.decoder(z)\n",
    "        return out, mu, logVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f1af71e224740dfa03fde8afa0dbffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "678aff9de9004b7aa65382b286baa778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "674502841e1d4541ad27a56292c1f1bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71980b15e0fc431a81ead3a796f6e510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gamzekecibas/opt/anaconda3/envs/comp541/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss 12369.232421875\n",
      "Epoch 1: Loss 10581.8544921875\n",
      "Epoch 2: Loss 11036.841796875\n",
      "Epoch 3: Loss 10736.0888671875\n",
      "Epoch 4: Loss 10051.28125\n",
      "Epoch 5: Loss 10119.712890625\n",
      "Epoch 6: Loss 9870.20703125\n",
      "Epoch 7: Loss 9967.1435546875\n",
      "Epoch 8: Loss 10251.7333984375\n",
      "Epoch 9: Loss 10011.3095703125\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Initialize Hyperparameters\n",
    "\"\"\"\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 10\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Create dataloaders to feed data into the neural network\n",
    "Default MNIST dataset is used and standard train/test split is performed\n",
    "\"\"\"\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=True, download=True,\n",
    "                    transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=False, transform=transforms.ToTensor()),\n",
    "    batch_size=1)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Initialize the network and the Adam optimizer\n",
    "\"\"\"\n",
    "net = VAE().to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Training the network for a given number of epochs\n",
    "The loss after every epoch is printed\n",
    "\"\"\"\n",
    "for epoch in range(num_epochs):\n",
    "    for idx, data in enumerate(train_loader, 0):\n",
    "        imgs, _ = data\n",
    "        imgs = imgs.to(device)\n",
    "\n",
    "        # Feeding a batch of images into the network to obtain the output image, mu, and logVar\n",
    "        out, mu, logVar = net(imgs)\n",
    "\n",
    "        # The loss is the BCE loss combined with the KL divergence to ensure the distribution is learnt\n",
    "        kl_divergence = 0.5 * torch.sum(-1 - logVar + mu.pow(2) + logVar.exp())\n",
    "        loss = F.binary_cross_entropy(out, imgs, size_average=False) + kl_divergence\n",
    "\n",
    "        # Backpropagation based on the loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print('Epoch {}: Loss {}'.format(epoch, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The following part takes a random image from test loader to feed into the VAE.\n",
    "Both the original image and generated image from the distribution are shown.\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for data in random.sample(list(test_loader), 1):\n",
    "        imgs, _ = data\n",
    "        imgs = imgs.to(device)\n",
    "        img = np.transpose(imgs[0].cpu().numpy(), [1,2,0])\n",
    "        plt.subplot(121)\n",
    "        plt.imshow(np.squeeze(img))\n",
    "        out, mu, logVAR = net(imgs)\n",
    "        outimg = np.transpose(out[0].cpu().numpy(), [1,2,0])\n",
    "        plt.subplot(122)\n",
    "        plt.imshow(np.squeeze(outimg))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp541",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e10f8bc3a9bab29f2213eb58f93eaced6738d931646fd1ebf4918884c5d9b1e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
