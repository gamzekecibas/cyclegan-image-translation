{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "## referance links\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import scipy\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.utils as vutils\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "from fid_metric import fid_metric as fid\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import Dataset\n",
    "import natsort\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "train_cat_path = \"D:/masa üstü/Hamza Proje Dosyalar/comp511-project/afhq/train/cat\"\n",
    "train_dog_path = \"D:/masa üstü/Hamza Proje Dosyalar/comp511-project/afhq/train/dog\"\n",
    "val_cat_path = \"D:/masa üstü/Hamza Proje Dosyalar/comp511-project/afhq/val/cat\"\n",
    "val_dog_path = \"D:/masa üstü/Hamza Proje Dosyalar/comp511-project/afhq/val/dog\"\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "manual_seed = 10\n",
    "num_epochs = 200\n",
    "decay_start_epoch = 5\n",
    "lr = 0.0002\n",
    "random.seed(manual_seed)\n",
    "torch.manual_seed(manual_seed)\n",
    "\n",
    "\n",
    "def read_images(path):\n",
    "    group1_images = []\n",
    "    group2_images = []\n",
    "    # Iterate through the directory containing the images\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            # Get the full path of the image\n",
    "            image_path = os.path.join(root, file)\n",
    "            # Check the folder name and add the image to the appropriate list\n",
    "            if \"cat\" in root:\n",
    "                group1_images.append(image_path)\n",
    "            elif \"dog\" in root:\n",
    "                group2_images.append(image_path)\n",
    "    return group1_images, group2_images\n",
    "\n",
    "batch_size = 1  ## 128\n",
    "num_workers = 2\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize((64,64)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,),(0.5,))])\n",
    "\n",
    "class CustomDataSet(Dataset):\n",
    "    def __init__(self, main_dir, transform):\n",
    "        self.main_dir = main_dir\n",
    "        self.transform = transform\n",
    "        all_imgs = os.listdir(main_dir)\n",
    "        self.total_imgs = natsort.natsorted(all_imgs)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.total_imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_loc = os.path.join(self.main_dir, self.total_imgs[idx])\n",
    "        image = Image.open(img_loc).convert(\"RGB\")\n",
    "        tensor_image = self.transform(image)\n",
    "        return tensor_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cat = CustomDataSet(train_cat_path, transform=transform)\n",
    "train_dog = CustomDataSet(train_dog_path, transform=transform)\n",
    "val_cat = CustomDataSet(val_cat_path, transform=transform)\n",
    "val_dog = CustomDataSet(val_dog_path, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataloader for each group of images\n",
    "load_train_A = DataLoader(train_cat, batch_size=batch_size, shuffle=True)\n",
    "load_train_B = DataLoader(train_dog, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "load_test_A = DataLoader(val_cat, batch_size=batch_size, shuffle=True)\n",
    "load_test_B = DataLoader(val_dog, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_iter(real_A,real_B, fake_B, i, epoch):\n",
    "    # save the images\n",
    "    vutils.save_image(real_A,\n",
    "            'cat_epoch_'+str(epoch)+\"_iter_\"+str(i)+'.png',\n",
    "            normalize=True)\n",
    "\n",
    "    vutils.save_image(real_B,\n",
    "            'dog_epoch_'+str(epoch)+\"_iter_\"+str(i)+'.png',\n",
    "            normalize=True)\n",
    "\n",
    "    vutils.save_image(fake_B,\n",
    "            'generated_dog_epoch_'+str(epoch)+\"_iter_\"+str(i)+'.png',\n",
    "            normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(3, 512, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ConvTranspose2d(64, 3, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "# # define the discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(512, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "# initialize the generator and discriminator\n",
    "netG = Generator().to(device)\n",
    "netD = Discriminator().to(device)\n",
    "\n",
    "### design a CYCLEGAN model reference https://nn.labml.ai/gan/cycle_gan/index.html\n",
    "class CycleGAN(nn.Module):\n",
    "    def __init__(self, generator, discriminator):\n",
    "        super().__init__()\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.generator(x)\n",
    "\n",
    "    def gen_loss(self, x):\n",
    "        # The generator loss\n",
    "        return -self.discriminator(self(x)).mean()\n",
    "\n",
    "    def disc_loss(self, x, y):\n",
    "        # The discriminator loss\n",
    "        return -(self.discriminator(x).mean() - self.discriminator(y).mean())\n",
    "\n",
    "    def cycle_loss(self, x, y):\n",
    "        # The cycle consistency loss\n",
    "        return (x - self(y)).abs().mean()\n",
    "\n",
    "    def identity_loss(self, x, y):\n",
    "        # The identity loss\n",
    "        return (x - y).abs().mean()\n",
    "\n",
    "# initialize the model\n",
    "model = CycleGAN(netG, netD)\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "# train the model\n",
    "def train():\n",
    "    vgg16 = models.vgg16(pretrained=True)\n",
    "\n",
    "    # remove the last layers (classifier)\n",
    "    vgg16 = torch.nn.Sequential(*list(vgg16.features)[:-1], vgg16.avgpool)\n",
    "    vgg16.eval()\n",
    "    feature_model = vgg16.to(device) \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (real_A, real_B) in enumerate(zip(load_train_A, load_train_B)):\n",
    "            real_A = real_A.to(device)\n",
    "            real_B = real_B.to(device)\n",
    "\n",
    "            # train the discriminator\n",
    "            optimizer.zero_grad()\n",
    "            fake_B = model(real_A)\n",
    "            fake_A = model(real_B)\n",
    "\n",
    "            # train the generator\n",
    "            optimizer.zero_grad()\n",
    "            loss_G = model.gen_loss(real_A) + model.gen_loss(real_B) + model.cycle_loss(real_A, fake_B) + model.cycle_loss(real_B, fake_A) + model.identity_loss(real_A, real_B) + model.identity_loss(real_B, real_A)\n",
    "            loss_G.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # train the discriminator\n",
    "            optimizer.zero_grad()\n",
    "            loss_D = model.disc_loss(real_A, fake_A) + model.disc_loss(real_B, fake_B)\n",
    "            loss_D.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i+1) % 100 == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss_D: {:.4f}, Loss_G: {:.4f}'\n",
    "                    .format(epoch + 1, num_epochs, i + 1, len(load_train_A), loss_D.item(), loss_G.item()))\n",
    "\n",
    "                wandb.log({\"loss_D\": loss_D.item(), \"loss_G\": loss_G.item()})\n",
    "\n",
    "                fid_score = fid(feature_model, real_B, fake_B)\n",
    "                #kid = calculate_kid(real_B, fake_B)\n",
    "                wandb.log({\"FID\": fid_score})\n",
    "                \n",
    "                #wandb.log({'grad_penalty': grad_penalty})\n",
    "                wandb.log({\"epoch\": epoch})\n",
    "\n",
    "\n",
    "                wandb.log({\"real_A\": [wandb.Image(real_A[0], caption=\"real_sample\")],\n",
    "                            \"real_B\": [wandb.Image(real_B[0], caption=\"reference_sample\")],\n",
    "                            \"fake_B\": [wandb.Image(fake_B[0], caption=\"generated_sample\")]})\n",
    "                 \n",
    "\n",
    "        # save the images\n",
    "        save_iter(real_A, real_B, fake_B, i, epoch)\n",
    "\n",
    "        # save the model\n",
    "        torch.save(model.state_dict(), 'model_epoch_'+str(epoch)+'.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgkecibas16\u001b[0m (\u001b[33mcomp511\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/gamzekecibas/Desktop/GIT/comp511-project/cyclegan-tutorial/wandb/run-20230123_132801-2g4qpdev</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/comp511/CGAN_TRANSLATION/runs/2g4qpdev\" target=\"_blank\">neat-galaxy-154</a></strong> to <a href=\"https://wandb.ai/comp511/CGAN_TRANSLATION\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "# initialize wandb\n",
    "torch.cuda.empty_cache()\n",
    "wandb.init(project=\"CGAN_TRANSLATION\", entity=\"comp511\")\n",
    "# train the model\n",
    "train()\n",
    "\n",
    "## run the script in terminal\n",
    "## python cgan_translation.py\n",
    "## It is observable in wandb page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp511",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2ed5703b2f23dcb610a814daa2cfe2635bd1ce57814df4186094d411b6aed1b1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
